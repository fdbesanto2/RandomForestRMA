---
title: "Data_setup"
author: "Rachel Schattman"
date: "February 19, 2019"
output:
  word_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# load libraries
```{r, echo=FALSE}
library(dplyr)
library(plyr)
library(randomForest)
library(Metrics)
library(rpart)
library(knitr)
```

# Helpful resources:
## https://www.r-bloggers.com/how-to-implement-random-forests-in-r/
## https://cran.r-project.org/web/packages/randomForest/randomForest.pdf 
## https://rpubs.com/mbaumer/randomForest 


```{r}
script_path <- "C:/Users/rschattman/Documents/Research/RandomForestRMA/data"
in_dir <- "C:/Users/rschattman/Documents/Research/RandomForestRMA/data"
out_dir <- "C:/Users/rschattman/Documents/Research/RandomForestRMA/output/data"
```

# Read in data and combine into single dataframe
```{r}
PAcip <- read.csv(file = "C:/Users/rschattman/Documents/Research/RandomForestRMA/data/monthly_prcp_PA.csv", header = TRUE, sep = ",")
PAloss <- read.csv(file = "C:/Users/rschattman/Documents/Research/RandomForestRMA/data/PAannuallosses.csv", header = TRUE, sep = ",")
PAbeta <-merge(PAcip, PAloss)
```

# Create new data frames with one dependent variable
``` {r}
head(PAbeta)
WetAcres <- PAbeta[,c("Year", "month", "StateCollege_PRCP", "Lebanon_PRCP", "Selinsgrove_PRCP", "WetAcres")]
WetDollars <- PAbeta[,c("Year", "month", "StateCollege_PRCP", "Lebanon_PRCP", "Selinsgrove_PRCP", "WetDollars")]
DryDollars <- PAbeta[,c("Year", "month", "StateCollege_PRCP", "Lebanon_PRCP", "Selinsgrove_PRCP", "DryDollars")]
DryAcres <- PAbeta[,c("Year", "month", "StateCollege_PRCP", "Lebanon_PRCP", "Selinsgrove_PRCP", "DryAcres")]
```

# Review data
```{r}
head(WetAcres)
str(WetAcres)
summary(WetAcres)
```

# Split into trainning, validation, and test sets
```{r}
set.seed(25)
assignment <- sample(1:3, size = nrow(WetAcres), prob = c(0.7, 0.15, 0.15), replace = TRUE)

Wettrain <- WetAcres[assignment == 1,]
Wetvalid <- WetAcres[assignment == 2,]
Wettest <- WetAcres[assignment == 3,]

summary(Wettrain)
summary(Wetvalid)
summary(Wettest)
```

# Create Random Forest Model and test performance metrics
## Wet Acres
```{r}
Mod1 <- randomForest(WetAcres ~ ., 
                     data = Wettrain, 
                     ntree = 500, 
                     #method = "anova", 
                     importance = TRUE)

print(Mod1)                                 # % of variance expalined is low. Tuning needed
summary(Mod1)
plot(Mod1)

pred <- predict(object = Mod1, newdata = Wettest)
RMSE_Mod1 <- rmse(actual = Wettest$WetAcres, #actual values
     predicted = pred)                       #predicted values
print(RMSE_Mod1/mean(Wettest$WetAcres))      #tells us the %of the mean represented by RMSE. AKA "coefficient of variation"



# Tune mtry using OOB error
set.seed(25)
#train_pred <- predict(object = Mod1, newdata = PAtrain)
res <- tuneRF(x = Wettrain,
              y = Wettrain$WetAcre,
              ntree = 500,
              stepfactor = 0.5,
              doBest=TRUE,        # Returns a random forest model with optimal mtry value
              importance = TRUE)
              #localImp = TRUE)
print(res)
plot(res)
res$importance
varImpPlot(res)                      
```

## Wet Dollars
```{r}
# Split into trainning, validation, and test sets
set.seed(25)
assignment <- sample(1:3, size = nrow(WetDollars), prob = c(0.7, 0.15, 0.15), replace = TRUE)

Wettrain2 <- WetDollars[assignment == 1,]
Wetvalid2 <- WetDollars[assignment == 2,]
Wettest2 <- WetDollars[assignment == 3,]

summary(Wettrain2)
summary(Wetvalid2)
summary(Wettest2)


Mod2 <- randomForest(WetDollars ~ ., 
                     data = Wettrain2, 
                     ntree = 500, 
                     #method = "anova", 
                     importance = TRUE)

print(Mod2)                                 # % of variance expalined is low. Tuning needed
summary(Mod2)
plot(Mod2)

pred2 <- predict(object = Mod2, newdata = Wettest2)
RMSE_Mod2 <- rmse(actual = Wettest2$WetDollars, #actual values
     predicted = pred2)                        #predicted values
print(RMSE_Mod2/mean(Wettest2$WetDollars))      #tells us the %of the mean represented by RMSE. AKA "coefficient of variation"


# Tune mtry using OOB error
set.seed(25)
#train_pred <- predict(object = Mod1, newdata = PAtrain)
res2 <- tuneRF(x = Wettrain2,
              y = Wettrain2$WetDollars,
              ntree = 500,
              stepfactor = 0.5,
              doBest=TRUE,        # Returns a random forest model with optimal mtry value
              importance = TRUE)
              #localImp = TRUE)
print(res2)
plot(res2)
res2$importance
varImpPlot(res2)                      
```
## Dry Acres
```{r}
# Split into trainning, validation, and test sets
set.seed(25)
assignment <- sample(1:3, size = nrow(DryAcres), prob = c(0.7, 0.15, 0.15), replace = TRUE)

Drytrain <- DryAcres[assignment == 1,]
Dryvalid <- DryAcres[assignment == 2,]
Drytest <- DryAcres[assignment == 3,]

summary(Drytrain)
summary(Dryvalid)
summary(Drytest)


Mod3 <- randomForest(DryAcres ~ ., 
                     data = Drytrain, 
                     ntree = 500, 
                     #method = "anova", 
                     importance = TRUE)

print(Mod3)                                 # % of variance expalined is low. Tuning needed
summary(Mod3)
plot(Mod3)

pred3 <- predict(object = Mod3, newdata = Drytest)
RMSE_Mod3 <- rmse(actual = Drytest$DryAcres, #actual values
     predicted = pred3)                        #predicted values
print(RMSE_Mod3/mean(Drytest$DryAcres))      #tells us the %of the mean represented by RMSE. AKA "coefficient of variation"


# Tune mtry using OOB error
set.seed(25)
#train_pred <- predict(object = Mod1, newdata = PAtrain)
res3 <- tuneRF(x = Drytrain,
              y = Drytrain$DryAcres,
              ntree = 500,
              stepfactor = 0.5,
              doBest=TRUE,        # Returns a random forest model with optimal mtry value
              importance = TRUE)
              #localImp = TRUE)
print(res3)
plot(res3)         # looks pretty choppy?
res3$importance
varImpPlot(res3)                      
```

## Dry Dollars
```{r}
# Split into trainning, validation, and test sets
set.seed(25)
assignment <- sample(1:3, size = nrow(DryDollars), prob = c(0.7, 0.15, 0.15), replace = TRUE)

Drytrain2 <- DryDollars[assignment == 1,]
Dryvalid2 <- DryDollars[assignment == 2,]
Drytest2 <- DryDollars[assignment == 3,]

summary(Drytrain2)
summary(Dryvalid2)
summary(Drytest2)


Mod4 <- randomForest(DryDollars ~ ., 
                     data = Drytrain2, 
                     ntree = 500, 
                     #method = "anova", 
                     importance = TRUE)

print(Mod4)                                 # % of variance expalined is low. Tuning needed
summary(Mod4)
plot(Mod4)

pred4 <- predict(object = Mod4, newdata = Drytest2)
RMSE_Mod4 <- rmse(actual = Drytest2$DryDollars, #actual values
     predicted = pred4)                        #predicted values
print(RMSE_Mod4/mean(Drytest2$DryDollars))      #tells us the %of the mean represented by RMSE. AKA "coefficient of variation"


# Tune mtry using OOB error
set.seed(25)
#train_pred <- predict(object = Mod1, newdata = PAtrain)
res4 <- tuneRF(x = Drytrain2,
              y = Drytrain2$DryDollars,
              ntree = 500,
              stepfactor = 0.5,
              doBest=TRUE,        # Returns a random forest model with optimal mtry value
              importance = TRUE)
              #localImp = TRUE)
print(res4)
plot(res4)         # looks pretty choppy?
res4$importance
varImpPlot(res4)                      
```









# Other optinos for fine tuning the model using control function
```{r}
Mod2 <- randomForest(WetAcres ~ ., 
                     data = Wettrain, 
                     ntree = 500, 
                     mtry = 6,                                        # based on tuneRF function results above
                     importance = TRUE,
                     control = rpart.control(minsplit = 20,           # default is 20
                                             cp = 0.01,               # default is 0.01
                                             maxdepth = 30))          # default is 30
print(Mod2)
summary(Mod2)
plot(Mod2)

pred <- predict(object = Mod2, newdata = Wettest)
RMSE_Mod2 <- rmse(actual = Wettest$WetAcres, #actual values
     predicted = pred)                       #predicted values
print(RMSE_Mod2/mean(Wettest$WetAcres))      #tells us the %of the mean represented by RMSE. AKA "coefficient of variation"

#start here in AM
#plotcp(Mod2)
#summary(rpart(Mod2))
```

# Predicting on train set and checking classification accuracy
```{r}
#predTrain <- predict(Mod2, PAtrain, type = "class")
#table(predTrain, PAtrain$DryAcres)  
```